---
title: "Politi-troll"
author: "Matt Cole"
date: "October 23, 2016"
output: pdf_document
subtitle: Identifying political trolls on Twitter
---

```{r load_packages_data, warning=F, echo=FALSE, message=FALSE, cache=T, results='hide',include=FALSE, error=F}
library(readr); library(sm);library(ggplot2); library(rpart); library(boot); library(sm); library(lubridate); library(rpart.plot); library(rpart); library(knitr); library(caret)
```
```{r setwd_source, warning=F, echo=FALSE, message=FALSE, cache=T, results='hide', include=FALSE, error=F}

setwd(file.path(".."))
#source('rscripts/editing.R')
source('rscripts/8_visuals.r')
data <- read_csv("data/MC_processed_data.csv")

lp <- function(x){
        y <- x/(1-x)
        y <- exp(y)
        return(y)
}

```

```{r trees, echo=FALSE, cache=T, message=FALSE, dependson = "load_packages_data", warning = F, warning=F}
library(boot)
set.seed(12)

fit <- rpart(troll~t_sent+created+followersCount+listedCount+statusesCount+favoritesCount+friendsCount+
                     lang+bdword+user_w+user_a+user_m + angry + imagedefault, 
              method = "class",
             weights = ifelse(data$troll == 1,2,1),
             data=data)

###
pfit <- prune(fit, cp=fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])

#summary(pfit)
par(mfrow=c(1, 1))

# plot the pruned tree 


#pfit$cptable

pred <- predict(fit, data) %>% as.data.frame() %>% cbind(data$troll) %>% as.tbl()
pred$p1 <- ifelse(pred[,2] > 0.5,1,0)
colnames(pred) <- c("prob0", "prob1", "troll", "predicted")

tree_err_rate<-1-mean(pred[,3] == pred[,4])
sensitivity<-mean(pred[pred$troll == 1,]$troll == pred[pred$troll == 1,]$predicted)
specificity <- mean(pred[pred$troll == 0,]$troll == pred[pred$troll == 0,]$predicted)

```


```{r logist, echo=FALSE, cache=T, message=FALSE, cache=F, dependson = "load_packages_data", , warning=F}
###
#### LOGISTIC REGRESSION 
### 

library(glmnet); library(boot)

logistic_fit1 <- glm(troll ~ t_sent, family = binomial(link = "logit"), data=data)
logistic_fit1_cv <- cv.glm(data, logistic_fit1, K = 10)
#logistic_fit1_cv$delta[1]

logistic_fit2 <- glm(troll~t_sent+followersCount+listedCount+favoritesCount+
                badwords+user_m  + imagedefault, 
                     family = binomial(link = "logit"), data=data)
logistic_fit2_cv <- cv.glm(data, logistic_fit2)
#logistic_fit2_cv$delta[2]

error_log1 <- mean((predict.glm(logistic_fit1, data,type="response") >= 0.5) == (data$troll == 1))
error_log2 <- mean((predict.glm(logistic_fit2, data,type="response") >= 0.5) == (data$troll == 1))
```
## Introduction

Internet trolls are considered a menace in nearly all online communities as they strive to generate emotional responses and cause disagreements between users (Stein, 2016). Motivations behind these users are unclear, but some social scientists suspect that a strange phenomenon known as the "disinhibition effect" may be to blame (Suler, 2005). Masked behind the apparent anonymity provided by many forms, sites, and the internet in general, social reservations that facilitate normal, face-to-face conversations can disappear, resulting in sometimes wild and rude behavior (Suler, 2005). This 'troll behavior' can stretch from simply posting the same status repeatedly to annoy and clog streams of information to violent threats and many 'things' in between. The effect of these trolls on Twitter, in particular, has been linked to many popular users leaving the platform entirely (Kim, 2016; Stein, 2016). The damage trolls may cause can affect more than just individuals however, with Twitter's troll problem considered to be partially responsible for Twitter's recent loss of 35 billion in market capitalization as potential company aquierers have backed out from making deals while popular users have left the platform because of trolling (Hern, 2016; Kim, 2016). While some trolls have made threats or otherwise broken laws, many have simply are an annoyance to both other users as well as the site in general, resulting in a loss of userbase. Because trolls are a neusance, it would be benificial to censor, block, or ban such users before they could conduct damage. In this project, we focused on identifying political trolls on Twitter, an area considered to be particularly saturated with such users. 


## Data

Twitter data collection began by identifying and collecting the usernames, also known as screen names, of accounts that have taken part in the political dialogue on Twitter. These usernames were collected from Twitter both through automated means in through the Twitter API and manually through the web app (https://www.twitter.com/) and was limited to English tweets (Gentry, 2012). 
The initial data collection consisted of searching twitter, via the twitteR API wrapper for users with tweets containing one of the two major political party presidential candidate's twitter username within the tweet text (@hillaryclinton or @realdonaldtrump). This collection occurred on October 1st, 2016 at 4:14:19 PM EST. Twitter API mechanics resulted in a mix of most recent tweets (up to the second), as well as 'hot' tweets that were somewhat recent and popular in terms of favorites and retweets. From these tweets, the usernames of the accounts publishing or retweeting the tweets were extracted and recorded. In total, of the 142 captured tweets, 142 usernames were obtained through this method. 
From October 7th through October 14th, because of a lack of trolls in the automatically sampled usernames, manual harvesting was conducted, consisting of browsing political figures tweets and responses, from the twitter web app (accessable at https://www.twitter.com/) while logged into our personal twitter account (@mattcol3), in an attempt to collect users with a higher proportion of trolls for modeling purposes. During this collection period, 132 additional usernames were added for a total of 274. 

Once the list of 274 users who have participated in the twitter political discourse was created, each user's 10 most recent tweets, as well as relevant tweet data (favorites, location, retweets, etc.) and data associated with the account (friends, description, etc.), were compiled. 
Using only the text from each user's 10 most recent tweets, including retweets and replies, users were classified as a troll or non-troll using the following scheme:
  
Trolls were defined as users with at least one of the previous 10 tweets appearing to be both:
  
* inflammatory: intended to arouse angry or violent feelings
*  extraneous: irrelevant or unrelated to the subject being dealt with

Ten tweets were chosen in an attempt to capture enough of each user's tweeting tendencies and classifying users as trolls with at least one inflammatory and extraneous tweet allows us to capture more subtle trolls. In total, all 274 users were classified as troll/non-troll after examining roughly 2,740 individual tweets.


## Methods

Using each users previous 10 tweets, we were able to construct average tweet sentiment using the AFINN lexicon. This lexicon comprises of English words each with an integer valued sentiment score manually determined by Finn Årup Nielsen from 2009-2011. Each word in the dictionary has a value between minus five (negative) and plus five (positive). Stop words, or words that likely will not contributed to the sentiment understanding of the sentence such as: as, the, is, at, which, or on, were removed prior to text analysis.  

Sentiment scores for each tweet were then calculated by summing together the values of each word. Then, a user sentiment score was generated by averaging the tweet AFINN sentiment scores over all recorded (10) tweets. Additionally, the NRC lexicon, which assigns scores to each of two sentiments (positive and negative) as well as eight emotions was used used to generate an 'angry' score comprising of anger, fear, and disgust subscores as well as a 'happy' score comprising of joy and trust emotion subscores. As emojis have become increasingly popular in today's web-based communication, an emoji dictionary was scrapped from http://www.unicode.org and emoji usage as well as sentiments were determined and averaged across tweets. When an emoji was identified, the keywords corresponding to the emoji were run through the AFINN lexicon to determine positivity or negativity associated with the emoji within the tweet. Forinstance (eye | face | grin | smile). Tweet source (how tweets were sent) was collected and divided into three categories, browser-based tweets, mobile tweets, and other tweet systems which included automated tweeting and unknown tweet sources. 

  
  Exploratory data analysis revealed that no single factor showed good separation, between trolls and non trolls (figure 1). Several covariates expected to have a strong relationship with troll status such as number of followers did not appear to show such in the 2 dimensional plots (figure 1). However, others such as AFINN sentiment score did show a possible relationship, although weak at best (figure 1).




```{r plots, warning=F, echo=FALSE, message=FALSE, cache=T, dependson = "load_packages_data"}
old.par <- par(mfrow=c(2, 2))
par(old.par)

par(mfrow=c(2, 2))

sm.density.compare(data$t_sent, data$troll, xlab="Sentiment Score",col=c("blue", "red"), lwd=2)

sm.density.compare(data$statusesCount, data$troll, xlab="status count",col=c("blue", "red"), lwd=2)
sm.density.compare(data$followersCount, data$troll, xlab="followers count",col=c("blue", "red"), lwd=2)
sm.density.compare(year(data$created), data$troll, xlab="date created",col=c("blue", "red"), lwd=2)
```
  
__Figure 1__ Smoothed density plots of common twitter metrics in both troll and non-troll groups. Trolls are denoted by the red line while non-trolls are denoted by the blue line. Distribution of AFINN sentiment score and year of account creation appear to potentially be different in the two groups while there is no noticeable difference in follower or status count. 


We focused on three models to predict troll status: a simple logistic regression, a 'full' logistic regression model with automatic variable selection as well as a classification tree. In order to assess model fit, 20% of the data was randomly partitioned to a designated 'testing' data set comprising of `r nrow(test)` observations, of which `r sum(test$troll)` are trolls. The remaining `r nrow(train)` users (including `r sum(test$train)` trolls) were used to construct all models which were tested by predicting the troll status of the test set.

Classification and regression trees (CART) are a group of supervised machine learning methods which construct decision tree models utilizing observed data. Unlike other popular methods for classification or regression, CART methods do not produce global models, where a single predictive formula is employed to make decisions or predictions over all observations (James et al., 2013). Instead, CART methods break down the feature space containing the observations into small subspaces (called recursive partitioning) until the subspaces can be represented by relatively simple models. Benefits of CART methods include its high level of interpretability, automatic variable selection, and ease of visualization. 

A classification tree was grown using the rpart package in R. Because of the unbalanced data set, we opted to weight the observations as such: non-troll observations were given a weight of 1 while troll observations were weighted as the ratio of non-trolls:trolls in the training set, `r round( mean(1-train$troll)/mean(train$troll), 3)`. The classification tree's nodes were pruned back by reducing the number of nodes to minimize the 10-fold cross-validated error rate (Figure 2). 

Logistic regression models the probability of a user being a troll for each observation $i$ ($p_i$) by treating the logit function, $log(\frac{p_i}{1-p_i})$ as a linear function of the covariates. In this study, a major limitation may be logistic regression's inability to capture non-linear trends associated with the covariates. However, this limitation can be partially overcome by the addition of splines or interaction terms. First, we examined a simple logistic regression only consisting of AFINN sentiment, to better understand the analysis and found a prediction error of `r 1-round(error_log1, 2)`. In addition, we see that without controlling for any other covariates, for each 1 unit decrease in average AFINN sentiment score, expected odds of being a troll increased by a factor of `r (-summary(logistic_fit1)$coeff[2,1])`. Another logistic model was fit, utilizing stepwise forward selection, increasing the number of covariates until weighted CV-10 error rates decreased. This method yielded  a model utilizing average AFINN sentiment score, the number of followers, number of lists the user is on, if the user is on mobile, if the user is using the 'default egg' photo, and the number of friends (people following) (table 1).


## Results

Both the simple logistic and full logistic models had error rates of `r round(log1_err_rate, 3)` and `r round(log2_err_rate, 3)` respectively with the simple logistic model having a slightly higher sensitivity but lower specificity compared with the full model. 


```{r printing_table , echo=FALSE, cache=T, message=FALSE}
library(printr); library(knitr); require(base)
x <- as.data.frame(round(summary(log2)$coeff,5))
rownames(x) <- c("Intercept",
                 "Average Tweet Sentiment (AFINN)",
                 "Follwers",
                 "Listed Count",
                 "Mobile User (binary)",
                 "Default Image (binary)",
                 "Number of Friends")
kable(x, digits = 3, caption = 'Logistic regression coefficients')
#exp(confint(logistic_fit2))
```
  
__Table 1__ exponentiated Logistic regression coefficients. 

For our classification tree, We found a CV prediction error rate of `r round(tree_err_rate,3)`, sensitivity of `r round(sensitivity,3)`, specificity of `r round(specificity, 3)`, and a AUC of `r round(tree_auc, 3)` (figure 1, table 2). This showed a considerably higher degree of accuracy compared with the logistic regression models that were produced. 

```{r echo=FALSE, cache=T, message=FALSE, dependson="trees"}
rpart.plot(pfit, type = 3, uniform=TRUE, 
     main="Pruned Classification Tree for Trolls", digits=2, tweak =1)

```
  
  __Figure 2__ Pruned regression tree visualization. Nodes indicate, prediction (0 or 1 for troll status), mean troll value, and percentage of data contained in each node. 









```{r, cache=T, echo=F}
require(knitr)
x1<-c(log1_err_rate, log1_sens, log1_spec, log1_auc)
x2<-c(log2_err_rate, log2_sens, log2_spec,log2_auc)
x3<-c(tree_err_rate, tree_sens, tree_spec, tree_auc)
x_all<-as.data.frame(rbind(x1,x2,x3))
rownames(x_all) <- c("Simple Logistic", "Full Logistic", "Regression Tree")
colnames(x_all) <- c("Error Rate", "Sensitivity", "Specificity", "AUC")
kable(round(x_all,2))
```

__Table 2__ raw error rate, Sensitivity, Specificity, and "AUC" comparison of all three models. 





## Discussion 

### Results
It was expected that the regression tree would be able to outperform the logistic regression as the relationship between covariates and troll status seem opaque at best and would likely be best modeled with a non-parametric method (table 2). As we saw, the classification tree was in fact able to outperform the logistic regression models with respect to error rate, sensitivity and AUC however, the specificity results were abysmal with a value of 0.55, suggesting that our model was barely better than flipping a coin for classification of non-trolls, and much worse in this regard than either of the logistic regression models (table 2).

logistic regression  `r round(log1_err_rate, 3)` to `r round(log2_err_rate, 3)`, while increasing the sensitivity (from `r round(log1_sens, 3)` to `r round(log2_sens, 3)`), specificity (from `r round(log1_spec, 3)` to `r round(log2_spec, 3)`), and the AUC (from `r round(log1_auc, 3)` to `r round(log2_auc, 3)`).

This study did shed light on a strange phenomena of different classes of trolls. From our anecdotal experience, there seemed to be three types or classes of twitter trolls.
  
* 'personal accounts' comprising of students, professionals, etc. whom occasionally say mean/emotionally charged things on twitter.
  
* bots: usually newly created, low tweet/follower/friend count which seem to spew politically charged propaganda.
  
* troll/fan pages: these accounts seem to be semi-autonomous as they respond to political figures (@therealdonaldtrmp, @hillaryclinton) almost instantaneously while also being able to respond to certain accounts in a thought out manner. These accounts have many tweets, were created long ago and have many followers. In fact, Fortune, POLITICO and the New York Magazine all have run stories of these 'bot armies'.

Surprisingly, many of the covaraites did not make the final model in either the logistic or classification tree case. These included the anger score, bot users, emoji score, etc. This could be because of a lack of relationship between these variables and troll status, or it could be due to the lack of data to identify such nuanced features.


### Limitations
The main limitation of this study was a lack of available data, particularly trolls. Although there were `r nrow(data)` observations there were only `r sum(data$troll)` trolls in our dataset, more would likely allow us to identify additional relationships and interactions between variables and troll status. In addition, there is the possibility for human error as a single person classified all tweets. This error could come from keystroke error or implicit political bias. Political bias could be difficult to identify and overcome where beliefs of what actually occurred could alter whether a statement is either inflammatory or extraneous. A good example of this are statements such as "Bill Clinton is a rapist", which were classified as both inflammatory and extraneous, but to an individual whom believes that the statement is true, would likely not view it as extraneous as it is simply stating the truth. 

### Generalization
It is plausible that these models could generalize to other spaces within twitter or even outside of the social media site where trolling is a serious issue. However, the model relies heavily on non-text covariates such as friends, dates, and followers and applying this model to,  an anonymous online form would likely be less effective, as this user data would be missing.  the models here may not generalize to  sites where the long posts are common as tweets are capped at 140 characters, however potentially averaging sentiments or bad words (ie. average sentiment per 100 characters or 10 words) may possibly be effective.

### Reproducibility
* with this project the tradeoff between reproducibility and both generalizability as well as relevance became apparent very quickly. "Did each user have 10 total tweets?  How did you define inflammatory or extraneous?  A bag of words?  Your judgment?" -John


### Future Work
In the future, it would be beneficial to further optimize tuning parameters associated with these models and inspect how other algorithms perform, particularly convolutional neural networks as well as support vector machines which may be able to identify additional hard to see relationships in the data resulting in better prediction accuracy. In addition, future work should include identifying word n-grams which may allow us to gain additional insight beyond lexicons. n-grams are popular in computational linguistics as two words in sequence contain additional information about the meaning of the sentence compared to lexicon analysis of the same two words. Future would could focus on classify individual tweets as troll / non-troll tweets or even non-binary degrees of 'troll', for instance, classifying three types of trolls mentioned earlier in the discussion. It would also be interesting to run a latent class analysis on the variables 





## Thank you

Thanks to Finn Årup Nielsen manually labeled the words in the AFINN lexicon from 2009-2011, which was used in this analysis.
  
Thank you to http://unicode.org/emoji/charts/full-emoji-list.html for letting me borrow the emoji database without asking.
  
##References: 

Hern, Alex. "Did Trolls Cost Twitter $3.5bn and Its Sale?" The Guardian. Guardian News and Media, 18 Oct. 2016. Web. 21 Oct. 2016.

James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An introduction to statistical learning (Vol. 6). New York: springer.

Kim, E. (2016, October 17). Twitter trolls were part of the reason why Salesforce walked away from a deal. Business Insider

Martin, J. H., & Jurafsky, D. (2000). Speech and language processing. International Edition, 710.

Stein, J. (2016, August 18). How Trolls Are Ruining the Internet. TIME

Suler, J. (2005). The online disinhibition effect. International Journal of Applied Psychoanalytic Studies, 2(2), 184-188.

## Packages

  
  Hadley Wickham, Jim Hester and Romain Francois (2016). readr: Read Tabular Data. R package version
  1.0.0. https://CRAN.R-project.org/package=readr
  
Bowman, A. W., & Azzalini, A. (2013). R package sm: nonparametric smoothing methods (version 2.2-5).
  
Therneau, T. M., Atkinson, B., & Ripley, B. (2010). rpart: Recursive Partitioning. R package version 3.1–42. Computer software program retrieved from http://CRAN. R-project. org/package= rpart.
  
Gentry, J. (2012). twitteR: R based Twitter client. R package version 0.99, 19.

Wickham, H., & Francois, R. (2015). dplyr: A grammar of data manipulation. R package version 0.4, 1, 20.